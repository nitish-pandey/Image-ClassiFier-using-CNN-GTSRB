# -*- coding: utf-8 -*-
"""GTSRB-CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/nitish-pandey/Image-ClassiFier-using-CNN--Cat-vs-Dog-/blob/main/GTSRB_CNN.ipynb

## Imports
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import random
import os

import tensorflow as tf
from tensorflow import keras
from keras import backend as k

from keras.models import Sequential
from keras.layers import Dense ,Conv2D,MaxPool2D, Dropout,Activation,BatchNormalization,Flatten
from keras.callbacks import EarlyStopping
from keras.regularizers import l2

from keras.preprocessing.image import ImageDataGenerator

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix,classification_report

"""## Data Download and preprocessing

Here , the data is downloaded directly from the url in zip format
"""

#Images for training
!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip
#Images for validation    
!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip
#Labels for validation
!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip

"""Unzipping the data"""

!unzip '/content/GTSRB_Final_Test_GT.zip'
!unzip '/content/GTSRB_Final_Test_Images.zip'
!unzip '/content/GTSRB_Final_Training_Images.zip'

training_directory='/content/GTSRB/Final_Training/Images'
test_directory='/content/GTSRB/Final_Test/Images'

train_generator=ImageDataGenerator(
    rescale=1./255,
    zoom_range=0.1,
    shear_range=0.1,
    validation_split=0.3
)
test_generator=ImageDataGenerator(rescale=1./255)

training_data=train_generator.flow_from_directory(
    training_directory,
    target_size=(64,64),
    color_mode='rgb',
    class_mode='categorical',
    subset='training'
)

validation_data=train_generator.flow_from_directory(
    training_directory,
    target_size=(64,64),
    color_mode='rgb',
    class_mode='categorical',
    subset='validation'
)

"""## Model Building and Training"""

model=Sequential()

# 1st convolution layer
model.add(Conv2D(64,kernel_size=(3,3),activation='relu',input_shape=(64,64,3),kernel_regularizer=l2(0.001)))
model.add(MaxPool2D(pool_size=(2,2)))


# 2nd convolution layer
model.add(Conv2D(16,kernel_size=(5,5),activation='relu',kernel_regularizer=l2(0.001)))
model.add(MaxPool2D(pool_size=(2,2)))


# 3rd convolution layer
model.add(Conv2D(32,kernel_size=(3,3),activation='relu',kernel_regularizer=l2(0.001)))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(BatchNormalization())


# Fully connected layer
model.add(Flatten())

model.add(Dense(units=256,activation='relu',kernel_regularizer=l2(0.001)))
model.add(Dropout(0.5))
model.add(BatchNormalization())

# Output layer
model.add(Dense(units=43,activation='sigmoid'))



model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
earlystop=EarlyStopping(patience=5)

model.fit(training_data,
          validation_data=validation_data,
          epochs=15,
          callbacks=[earlystop],
          steps_per_epoch=100
          )

"""### Visualizing the training preformance"""

model_log=model.history
acc=model_log.history['accuracy']
val_acc=model_log.history['val_accuracy']
loss=model_log.history['loss']
val_loss=model_log.history['val_loss']
epochs=range(1,len(acc)+1)

plt.figure(figsize=(10,6))
plt.subplot(1,2,1)
plt.plot(epochs,acc,label='Training Accuracy ',color='r')
plt.plot(epochs,val_acc,label='Validation Accuracy',color='b')
plt.xlabel('Epochs ---->>')
plt.ylabel('Accuracy ---->>')
plt.legend(['Train','Validation'])
plt.title("Training v/s Validation Accuracy")

plt.subplot(1,2,2)
plt.plot(epochs,loss,label='Training Loss ',color='r')
plt.plot(epochs,val_loss,label='Validation Loss',color='b')
plt.xlabel('Epochs ---->> ')
plt.ylabel('Loss ---->> ')
plt.legend(['Train','Validation'])
plt.title("Training v/s Validation Loss")
plt.show()


plt.show()

"""### Model Saving"""

model.save('my_model.h5')

model.save_weights('model_weights.h5')